{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/debnatho/anaconda3/envs/scanpy_scgen/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata \n",
    "import celltypist\n",
    "from celltypist import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "VL_AAACCTGAGATCCCGC-1_1      Villi_early\n",
       "VL_AAACCTGAGGACAGAA-1_1      Villi_early\n",
       "VL_AAACCTGAGGCTAGGT-1_1      Villi_early\n",
       "VL_AAACCTGCAAGCGAGT-1_1      Villi_early\n",
       "VL_AAACCTGCAATCACAC-1_1      Villi_early\n",
       "                                ...     \n",
       "DC_TTTGGTTTCATCGGAT-1_22    Decidua_late\n",
       "DC_TTTGGTTTCTGATTCT-1_22    Decidua_late\n",
       "DC_TTTGTCAAGTTGTAGA-1_22    Decidua_late\n",
       "DC_TTTGTCACAGCTGTGC-1_22    Decidua_late\n",
       "DC_TTTGTCACATTATCTC-1_22    Decidua_late\n",
       "Name: tissue_time, Length: 101031, dtype: category\n",
       "Categories (4, object): ['Decidua_early', 'Decidua_late', 'Villi_early', 'Villi_late']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the early normalized data (H5AD) file from 2021 submission:\n",
    "adata_train = sc.read_h5ad(\"/data/analysis/preeclampsia_2019/analysis/images/Final_umap_nature/Placenta_normalized_Seurat_markers.h5ad\")\n",
    "adata_train.obs['tissue_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "DC_AAACCTGAGAAACGAG-1_4             dTcell\n",
       "DC_AAACCTGAGAAGCCCA-1_4               dEpC\n",
       "DC_AAACCTGAGACCTAGG-1_4             dTcell\n",
       "DC_AAACCTGAGACTAAGT-1_4     dMAC_classical\n",
       "DC_AAACCTGAGCACGCCT-1_4     dMAC_classical\n",
       "                                 ...      \n",
       "DC_TTTGGTTTCATCGGAT-1_22            dTcell\n",
       "DC_TTTGGTTTCTGATTCT-1_22    dMAC_activated\n",
       "DC_TTTGTCAAGTTGTAGA-1_22              dSMC\n",
       "DC_TTTGTCACAGCTGTGC-1_22             DSC_2\n",
       "DC_TTTGTCACATTATCTC-1_22    dMAC_activated\n",
       "Name: cell_type_semifinal_v2, Length: 40725, dtype: category\n",
       "Categories (22, object): ['DSC_1', 'DSC_2', 'dDC', 'dEVT', ..., 'dSCT', 'dSMC', 'dTcell', 'dVEC']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build a custom model on the control decidua (early & late term):  \n",
    "subset= ['Decidua_early', 'Decidua_late']\n",
    "adata_train= adata_train[adata_train.obs['tissue_time'].isin(subset)]\n",
    "adata_train.obs['cell_type_semifinal_v2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DSC_1', 'DSC_2', 'dDC', 'dEVT', 'dEpC', 'dFB_1', 'dFB_2',\n",
       "       'dGranulocyte', 'dLEC', 'dLEC_dysfunctional', 'dMAC_activated',\n",
       "       'dMAC_classical', 'dMSC', 'dMonocyte', 'dNK_1', 'dNK_2', 'dNK_prol',\n",
       "       'dPlasmaCell', 'dSCT', 'dSMC', 'dTcell', 'dVEC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_train.obs['cell_type_semifinal_v2'].cat.categories #categories in decidua "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 27750 × 26115\n",
       "    obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'stim', 'percent.mt', 'S.Score', 'G2M.Score', 'Phase', 'old.ident', 'integrated_snn_res.0.5', 'seurat_clusters', 'group', 'disease', 'time', 'tissue', 'tissue_time', 'integrated_snn_res.1', 'integrated_snn_res.2', 'integrated_snn_res.3', 'cell_type', 'RNA_snn_res.0.8', 'Merged_cell_type_PC35', 'cell_type_merged', 'sub_cluster', 'sub_cluster_final', 'cell_type_semifinal', 'cell_type_semifinal_v2'\n",
       "    uns: 'cell_type_semifinal_colors', 'umap_density_disease_params', 'umap_density_group_params', 'umap_density_params', 'umap_density_tissue_params'\n",
       "    obsm: 'X_umap'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter control cells only:\n",
    "adata_train= adata_train[adata_train.obs['disease']== 'C']\n",
    "adata_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dEpC                  6656\n",
       "dMAC_classical        4483\n",
       "dNK_1                 4417\n",
       "dTcell                2849\n",
       "dMAC_activated        1570\n",
       "dNK_2                 1444\n",
       "dLEC                  1313\n",
       "dVEC                  1184\n",
       "DSC_1                  783\n",
       "dSMC                   552\n",
       "dPlasmaCell            529\n",
       "dMSC                   476\n",
       "dNK_prol               361\n",
       "dGranulocyte           285\n",
       "dFB_1                  185\n",
       "dMonocyte              165\n",
       "DSC_2                  148\n",
       "dFB_2                  146\n",
       "dDC                    137\n",
       "dEVT                    31\n",
       "dLEC_dysfunctional      26\n",
       "dSCT                    10\n",
       "Name: cell_type_semifinal_v2, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Subset cell types/states of interest:\n",
    "subset= ['DSC_1', 'DSC_2', 'dDC', 'dEVT', 'dEpC', 'dFB_1', 'dFB_2','dGranulocyte', 'dLEC', 'dLEC_dysfunctional', \n",
    "         'dMAC_activated','dMAC_classical', 'dMSC', 'dMonocyte', 'dNK_1', 'dNK_2', 'dNK_prol',\n",
    "       'dPlasmaCell', 'dSCT', 'dSMC', 'dTcell', 'dVEC']\n",
    "\n",
    "#Training dataset for decidua: \n",
    "adata_train_dec= adata_train[adata_train.obs['cell_type_semifinal_v2'].isin(subset)]\n",
    "adata_train_dec.obs['cell_type_semifinal_v2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from celltypist.models import Model\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "set_level = logger.setLevel\n",
    "info = logger.info\n",
    "warn = logger.warning\n",
    "error = logger.error\n",
    "debug = logger.debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from anndata import AnnData\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from typing import Optional, Union\n",
    "from celltypist.models import Model\n",
    "from . import logger\n",
    "from scipy.sparse import spmatrix\n",
    "from datetime import datetime\n",
    "\n",
    "def _to_vector(_vector_or_file):\n",
    "    \"\"\"\n",
    "    For internal use. Turn a file into an array.\n",
    "    \"\"\"\n",
    "    if isinstance(_vector_or_file, str):\n",
    "        try:\n",
    "            return pd.read_csv(_vector_or_file, header=None)[0].values\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"🛑 {e}\")\n",
    "    else:\n",
    "        return _vector_or_file\n",
    "\n",
    "def _to_array(_array_like) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    For internal use. Turn an array-like object into an array.\n",
    "    \"\"\"\n",
    "    if isinstance(_array_like, pd.DataFrame):\n",
    "        return _array_like.values\n",
    "    elif isinstance(_array_like, spmatrix):\n",
    "        return _array_like.toarray()\n",
    "    elif isinstance(_array_like, np.matrix):\n",
    "        return np.array(_array_like)\n",
    "    elif isinstance(_array_like, np.ndarray):\n",
    "        return _array_like\n",
    "    else:\n",
    "        raise ValueError(f\"🛑 Please provide a valid array-like object as input\")\n",
    "\n",
    "def _prepare_data(X, labels, genes, transpose) -> tuple:\n",
    "    \"\"\"\n",
    "    For internal use. Prepare data for celltypist training.\n",
    "    \"\"\"\n",
    "    if (X is None) or (labels is None):\n",
    "        raise Exception(\"🛑 Missing training data and/or training labels. Please provide both arguments\")\n",
    "    if isinstance(X, AnnData) or (isinstance(X, str) and X.endswith('.h5ad')):\n",
    "        adata = sc.read(X) if isinstance(X, str) else X\n",
    "        adata.var_names_make_unique()\n",
    "        if adata.X.min() < 0:\n",
    "            logger.info(\"👀 Detected scaled expression in the input data, will try the .raw attribute\")\n",
    "            try:\n",
    "                indata = adata.raw.X.copy()\n",
    "                genes = adata.raw.var_names.copy()\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"🛑 Fail to use the .raw attribute in the input object. {e}\")\n",
    "        else:\n",
    "            indata = adata.X.copy()\n",
    "            genes = adata.var_names.copy()\n",
    "        if isinstance(labels, str) and (labels in adata.obs):\n",
    "            labels = adata.obs[labels]\n",
    "        else:\n",
    "            labels = _to_vector(labels)\n",
    "    elif isinstance(X, str) and X.endswith(('.csv', '.txt', '.tsv', '.tab', '.mtx', '.mtx.gz')):\n",
    "        adata = sc.read(X)\n",
    "        if transpose:\n",
    "            adata = adata.transpose()\n",
    "        if X.endswith(('.mtx', '.mtx.gz')):\n",
    "            if genes is None:\n",
    "                raise Exception(\"🛑 Missing `genes`. Please provide this argument together with the input mtx file\")\n",
    "            genes = _to_vector(genes)\n",
    "            if len(genes) != adata.n_vars:\n",
    "                raise ValueError(f\"🛑 The number of genes provided does not match the number of genes in {X}\")\n",
    "            adata.var_names = np.array(genes)\n",
    "        adata.var_names_make_unique()\n",
    "        if not float(adata.X.max()).is_integer():\n",
    "            logger.warn(f\"⚠️ Warning: the input file seems not a raw count matrix. The trained model may be biased\")\n",
    "        sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "        sc.pp.log1p(adata)\n",
    "        indata = adata.X.copy()\n",
    "        genes = adata.var_names.copy()\n",
    "        labels = _to_vector(labels)\n",
    "    elif isinstance(X, str):\n",
    "        raise ValueError(\"🛑 Invalid input. Supported types: .csv, .txt, .tsv, .tab, .mtx, .mtx.gz and .h5ad\")\n",
    "    else:\n",
    "        logger.info(\"👀 The input training data is processed as an array-like object\")\n",
    "        indata = X.copy()\n",
    "        if transpose:\n",
    "            indata = indata.transpose()\n",
    "        if isinstance(indata, pd.DataFrame):\n",
    "            genes = indata.columns.copy()\n",
    "        else:\n",
    "            if genes is None:\n",
    "                raise Exception(\"🛑 Missing `genes`. Please provide this argument together with the input training data\")\n",
    "            genes = _to_vector(genes)\n",
    "        labels = _to_vector(labels)\n",
    "    return indata, labels, genes\n",
    "\n",
    "def _LRClassifier(indata, labels, C, solver, max_iter, n_jobs, **kwargs) -> LogisticRegression:\n",
    "    \"\"\"\n",
    "    For internal use. Get the logistic Classifier.\n",
    "    \"\"\"\n",
    "    no_cells = len(labels)\n",
    "    if solver is None:\n",
    "        solver = 'sag' if no_cells>50000 else 'lbfgs'\n",
    "    elif solver not in ('liblinear', 'lbfgs', 'newton-cg', 'sag', 'saga'):\n",
    "        raise ValueError(f\"🛑 Invalid `solver`, should be one of `liblinear`, `lbfgs`, `newton-cg`, `sag`, and `saga`\")\n",
    "    logger.info(f\"🏋️ Training data using logistic regression\")\n",
    "    if no_cells > 100000:\n",
    "        logger.warn(f\"⚠️ Warning: it may take a long time to train this dataset with {no_cells} cells, try to decrease `max_iter` if the training does not finish in practical time\")\n",
    "    classifier = LogisticRegression(C = C, solver = solver, max_iter = max_iter, multi_class = 'ovr', n_jobs = n_jobs, **kwargs)\n",
    "    classifier.fit(indata, labels)\n",
    "    return classifier\n",
    "\n",
    "def _SGDClassifier(indata, labels,\n",
    "                   alpha, max_iter, n_jobs,\n",
    "                   mini_batch, batch_number, batch_size, epochs, balance_cell_type, **kwargs) -> SGDClassifier:\n",
    "    \"\"\"\n",
    "    For internal use. Get the SGDClassifier.\n",
    "    \"\"\"\n",
    "    classifier = SGDClassifier(loss = 'log', alpha = alpha, max_iter = max_iter, n_jobs = n_jobs, **kwargs)\n",
    "    if not mini_batch:\n",
    "        logger.info(f\"🏋️ Training data using SGD logistic regression\")\n",
    "        if len(labels) > 100000:\n",
    "            logger.warn(f\"⚠️ Warning: it may take a long time to train this dataset with {len(labels)} cells, try to decrease `max_iter` if the training does not finish in practical time\")\n",
    "        classifier.fit(indata, labels)\n",
    "    else:\n",
    "        logger.info(f\"🏋️ Training data using mini-batch SGD logistic regression\")\n",
    "        no_cells = len(labels)\n",
    "        if no_cells < 10000:\n",
    "            logger.warn(f\"⚠️ Warning: the number of cells ({no_cells}) is not big enough to conduct a proper mini-batch training. You may consider using traditional SGD classifier (mini_batch = False)\")\n",
    "        if no_cells <= batch_size:\n",
    "            raise ValueError(f\"🛑 Number of cells ({no_cells}) is fewer than the batch size ({batch_size}). Decrease `batch_size`, or use SGD directly (mini_batch = False)\")\n",
    "        no_cells_sample = min([batch_number*batch_size, no_cells])\n",
    "        starts = np.arange(0, no_cells_sample, batch_size)\n",
    "        if balance_cell_type:\n",
    "            celltype_freq = np.unique(labels, return_counts = True)\n",
    "            len_celltype = len(celltype_freq[0])\n",
    "            mapping = pd.Series(1 / (celltype_freq[1]*len_celltype), index = celltype_freq[0])\n",
    "            p = mapping[labels].values\n",
    "        for epoch in range(1, (epochs+1)):\n",
    "            logger.info(f\"⏳ Epochs: [{epoch}/{epochs}]\")\n",
    "            if not balance_cell_type:\n",
    "                sampled_cell_index = np.random.choice(no_cells, no_cells_sample, replace = False)\n",
    "            else:\n",
    "                sampled_cell_index = np.random.choice(no_cells, no_cells_sample, replace = False, p = p)\n",
    "            for start in starts:\n",
    "                classifier.partial_fit(indata[sampled_cell_index[start:start+batch_size]], labels[sampled_cell_index[start:start+batch_size]], classes = np.unique(labels))\n",
    "    return classifier\n",
    "\n",
    "def train(X = None,\n",
    "          labels: Optional[Union[str, list, tuple, np.ndarray, pd.Series, pd.Index]] = None,\n",
    "          genes: Optional[Union[str, list, tuple, np.ndarray, pd.Series, pd.Index]] = None,\n",
    "          transpose_input: bool = False,\n",
    "          check_expression: bool = True,\n",
    "          #LR param\n",
    "          C: float = 1.0, solver: Optional[str] = None, max_iter: int = 1000, n_jobs: Optional[int] = None,\n",
    "          #SGD param\n",
    "          use_SGD: bool = False, alpha: float = 0.0001,\n",
    "          #mini-batch\n",
    "          mini_batch: bool = False, batch_number: int = 100, batch_size: int = 1000, epochs: int = 10, balance_cell_type: bool = False,\n",
    "          #feature selection\n",
    "          feature_selection: bool = False, top_genes: int = 500,\n",
    "          #description\n",
    "          date: str = '', details: str = '', url: str = '',\n",
    "          #other SGD param\n",
    "          **kwargs\n",
    "         ) -> Model:\n",
    "    \"\"\"\n",
    "    Train a celltypist model using mini-batch (optional) logistic classifier with a global solver or stochastic gradient descent (SGD) learning.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X\n",
    "        Path to the input count matrix (supported types are csv, txt, tsv, tab and mtx) or AnnData (h5ad).\n",
    "        Also accepts the input as an :class:`~anndata.AnnData` object, or any array-like objects already loaded in memory.\n",
    "        See `check_expression` for detailed format requirements.\n",
    "        A cell-by-gene format is desirable (see `transpose_input` for more information).\n",
    "    labels\n",
    "        Path to the file containing cell type label per line corresponding to the cells in `X`.\n",
    "        Also accepts any list-like objects already loaded in memory (such as an array).\n",
    "        If `X` is specified as an AnnData, this argument can also be set as a column name from cell metadata.\n",
    "    genes\n",
    "        Path to the file containing one gene per line corresponding to the genes in `X`.\n",
    "        Also accepts any list-like objects already loaded in memory (such as an array).\n",
    "        Note `genes` will be extracted from `X` where possible (e.g., `X` is an AnnData or data frame).\n",
    "    transpose_input\n",
    "        Whether to transpose the input matrix. Set to `True` if `X` is provided in a gene-by-cell format.\n",
    "        (Default: `False`)\n",
    "    check_expression\n",
    "        Check whether the expression matrix in the input data is supplied as required.\n",
    "        Except the case where a path to the raw count table file is specified, all other inputs for `X` should be in log1p normalized expression to 10000 counts per cell.\n",
    "        Set to `False` if you want to train the data regardless of the expression formats.\n",
    "        (Default: `True`)\n",
    "    C\n",
    "        Inverse of L2 regularization strength for traditional logistic classifier. A smaller value can possibly improve model generalization while at the cost of decreased accuracy.\n",
    "        This argument is ignored if SGD learning is enabled (`use_SGD = True`).\n",
    "        (Default: 1.0)\n",
    "    solver\n",
    "        Algorithm to use in the optimization problem for traditional logistic classifier.\n",
    "        The default behavior is to choose the solver according to the size of the input data.\n",
    "        This argument is ignored if SGD learning is enabled (`use_SGD = True`).\n",
    "    max_iter\n",
    "        Maximum number of iterations before reaching the minimum of the cost function.\n",
    "        Try to decrease `max_iter` if the cost function does not converge for a long time.\n",
    "        This argument is for both traditional and SGD logistic classifiers, and will be ignored if mini-batch SGD training is conducted (`use_SGD = True` and `mini_batch = True`).\n",
    "        (Default: 1000)\n",
    "    n_jobs\n",
    "        Number of CPUs used. Default to one CPU. `-1` means all CPUs are used.\n",
    "        This argument is for both traditional and SGD logistic classifiers.\n",
    "    use_SGD\n",
    "        Whether to implement SGD learning for the logistic classifier.\n",
    "        (Default: `False`)\n",
    "    alpha\n",
    "        L2 regularization strength for SGD logistic classifier. A larger value can possibly improve model generalization while at the cost of decreased accuracy.\n",
    "        This argument is ignored if SGD learning is disabled (`use_SGD = False`).\n",
    "        (Default: 0.0001)\n",
    "    mini_batch\n",
    "        Whether to implement mini-batch training for the SGD logistic classifier.\n",
    "        Setting to `True` may improve the training efficiency for large datasets (for example, >100k cells).\n",
    "        This argument is ignored if SGD learning is disabled (`use_SGD = False`).\n",
    "        (Default: `False`)\n",
    "    batch_number\n",
    "        The number of batches used for training in each epoch. Each batch contains `batch_size` cells.\n",
    "        For datasets which cannot be binned into `batch_number` batches, all batches will be used.\n",
    "        This argument is relevant only if mini-batch SGD training is conducted (`use_SGD = True` and `mini_batch = True`).\n",
    "        (Default: 100)\n",
    "    batch_size\n",
    "        The number of cells within each batch.\n",
    "        This argument is relevant only if mini-batch SGD training is conducted (`use_SGD = True` and `mini_batch = True`).\n",
    "        (Default: 1000)\n",
    "    epochs\n",
    "        The number of epochs for the mini-batch training procedure.\n",
    "        The default values of `batch_number`, `batch_size`, and `epochs` together allow observing ~10^6 training cells.\n",
    "        This argument is relevant only if mini-batch SGD training is conducted (`use_SGD = True` and `mini_batch = True`).\n",
    "        (Default: 10)\n",
    "    balance_cell_type\n",
    "        Whether to balance the cell type frequencies in mini-batches during each epoch.\n",
    "        Setting to `True` will sample rare cell types with a higher probability, ensuring close-to-even cell type distributions in mini-batches.\n",
    "        This argument is relevant only if mini-batch SGD training is conducted (`use_SGD = True` and `mini_batch = True`).\n",
    "        (Default: `False`)\n",
    "    feature_selection\n",
    "        Whether to perform two-pass data training where the first round is used for selecting important features/genes.\n",
    "        If `True`, the training time will be approximately doubled.\n",
    "        (Default: `False`)\n",
    "    top_genes\n",
    "        The number of top genes selected from each class/cell-type based on their absolute regression coefficients.\n",
    "        The final feature set is combined across all classes (i.e., union).\n",
    "        (Default: 500)\n",
    "    date\n",
    "        Free text of the date of the model. Default to the time when the training is completed.\n",
    "    details\n",
    "        Free text of the description of the model.\n",
    "    url\n",
    "        Free text of the (possible) download url of the model.\n",
    "    **kwargs\n",
    "        Other keyword arguments passed to :class:`~sklearn.linear_model.LogisticRegression` (`use_SGD = False`) or :class:`~sklearn.linear_model.SGDClassifier` (`use_SGD = True`).\n",
    "    Returns\n",
    "    ----------\n",
    "    :class:`~celltypist.models.Model`\n",
    "        An instance of the :class:`~celltypist.models.Model` trained by celltypist.\n",
    "    \"\"\"\n",
    "    #prepare\n",
    "    logger.info(\"🍳 Preparing data before training\")\n",
    "    indata, labels, genes = _prepare_data(X, labels, genes, transpose_input)\n",
    "    indata = _to_array(indata)\n",
    "    labels = np.array(labels)\n",
    "    genes = np.array(genes)\n",
    "    #check\n",
    "    if check_expression and (np.abs(np.expm1(indata[0]).sum()-10000) > 1):\n",
    "        raise ValueError(\"🛑 Invalid expression matrix, expect log1p normalized expression to 10000 counts per cell\")\n",
    "    if len(labels) != indata.shape[0]:\n",
    "        raise ValueError(f\"🛑 Length of training labels ({len(labels)}) does not match the number of input cells ({indata.shape[0]})\")\n",
    "    if len(genes) != indata.shape[1]:\n",
    "        raise ValueError(f\"🛑 The number of genes ({len(genes)}) provided does not match the number of genes in the training data ({indata.shape[1]})\")\n",
    "    #filter\n",
    "    flag = indata.sum(axis = 0) == 0\n",
    "    if flag.sum() > 0:\n",
    "        logger.info(f\"✂️ {flag.sum()} non-expressed genes are filtered out\")\n",
    "        indata = indata[:, ~flag]\n",
    "        genes = genes[~flag]\n",
    "    #scaler\n",
    "    logger.info(f\"⚖️ Scaling input data\")\n",
    "    scaler = StandardScaler()\n",
    "    indata = scaler.fit_transform(indata)\n",
    "    indata = np.clip(indata, a_min = None, a_max = 10)\n",
    "    #classifier\n",
    "    if use_SGD:\n",
    "        classifier = _SGDClassifier(indata = indata, labels = labels, alpha = alpha, max_iter = max_iter, n_jobs = n_jobs, mini_batch = mini_batch, batch_number = batch_number, batch_size = batch_size, epochs = epochs, balance_cell_type = balance_cell_type, **kwargs)\n",
    "    else:\n",
    "        classifier = _LRClassifier(indata = indata, labels = labels, C = C, solver = solver, max_iter = max_iter, n_jobs = n_jobs, **kwargs)\n",
    "    #feature selection -> new classifier and scaler\n",
    "    if feature_selection:\n",
    "        logger.info(f\"🔎 Selecting features\")\n",
    "        if len(genes) <= top_genes:\n",
    "            raise ValueError(f\"🛑 The number of genes ({len(genes)}) is fewer than the `top_genes` ({top_genes}). Unable to perform feature selection\")\n",
    "        gene_index = np.argpartition(np.abs(classifier.coef_), -top_genes, axis = 1)[:, -top_genes:]\n",
    "        gene_index = np.unique(gene_index)\n",
    "        logger.info(f\"🧬 {len(gene_index)} features are selected\")\n",
    "        genes = genes[gene_index]\n",
    "        indata = indata[:, gene_index]\n",
    "        logger.info(f\"🏋️ Starting the second round of training\")\n",
    "        if use_SGD:\n",
    "            classifier = _SGDClassifier(indata = indata, labels = labels, alpha = alpha, max_iter = max_iter, n_jobs = n_jobs, mini_batch = mini_batch, batch_number = batch_number, batch_size = batch_size, epochs = epochs, balance_cell_type = balance_cell_type, **kwargs)\n",
    "        else:\n",
    "            classifier = _LRClassifier(indata = indata, labels = labels, C = C, solver = solver, max_iter = max_iter, n_jobs = n_jobs, **kwargs)\n",
    "        scaler.mean_ = scaler.mean_[gene_index]\n",
    "        scaler.var_ = scaler.var_[gene_index]\n",
    "        scaler.scale_ = scaler.scale_[gene_index]\n",
    "        scaler.n_features_in_ = len(gene_index)\n",
    "    #model finalization\n",
    "    classifier.features = genes\n",
    "    if not date:\n",
    "        date = str(datetime.now())\n",
    "    description = {'date': date, 'details': details, 'url': url, 'number_celltypes': len(classifier.classes_)}\n",
    "    logger.info(f\"✅ Model training done!\")\n",
    "    #return Model(classifier, scaler, description)\n",
    "    return Model(classifier, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(early_model, file: str) -> None:\n",
    "        \"\"\"Write out the model.\"\"\"\n",
    "        obj = dict(Model = early_model.classifier, Scaler_ = early_model.scaler)\n",
    "        file = os.path.splitext(file)[0] + '.pkl'\n",
    "        with open(file, 'wb') as output:\n",
    "            pickle.dump(obj, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🍳 Preparing data before training\n",
      "✂️ 1457 non-expressed genes are filtered out\n",
      "⚖️ Scaling input data\n",
      "🏋️ Training data using logistic regression\n",
      "✅ Model training done!\n"
     ]
    }
   ],
   "source": [
    "#Train model on the \"adata_train_dec\"\n",
    "decidua_model = train(adata_train_dec, labels = 'cell_type_semifinal_v2') #done!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import json\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, Union\n",
    "from scipy.special import expit\n",
    "from . import logger\n",
    "\n",
    "#Note that, this model serves as a template for supervised classification of samples bases on 2021 annotations. \n",
    "write(decidua_model, '/data/analysis/preeclampsia_2019/placenta_atlas_2022/placenta_celltypist_model/model_from_sp014_control_decidua.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📁 Input file is '/data/analysis/preeclampsia_2019/placenta_atlas_2022/decidua_anndata/Decidua_cellbender_normalized_matrix_270122.h5ad'\n",
      "⏳ Loading data...\n",
      "🔬 Input data has 44232 cells and 26603 genes\n",
      "🧙 Matching reference genes\n",
      "🧩 24619 features used for prediction\n",
      "🧙 Scaling input data\n",
      "🖋️ Predicting labels\n",
      "✅ Prediction done!\n",
      "🧙 Over-clustering input data with resolution set to 20\n",
      "/home/debnatho/anaconda3/envs/scanpy_scgen/lib/python3.6/site-packages/scanpy/utils.py:618: DeprecationWarning: Use is_view instead of isview, isview will be removed in the future.\n",
      "  if adata.isview:\n",
      "/home/debnatho/anaconda3/envs/scanpy_scgen/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:89: DeprecationWarning: Use is_view instead of isview, isview will be removed in the future.\n",
      "  if adata.isview:  # we shouldn't need this here...\n",
      "/home/debnatho/anaconda3/envs/scanpy_scgen/lib/python3.6/site-packages/numba/typed_passes.py:293: NumbaPerformanceWarning: \u001b[1m\n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\u001b[1m\n",
      "File \"../../../../../home/debnatho/anaconda3/envs/scanpy_scgen/lib/python3.6/site-packages/umap/rp_tree.py\", line 135:\u001b[0m\n",
      "\u001b[1m@numba.njit(fastmath=True, nogil=True, parallel=True)\n",
      "\u001b[1mdef euclidean_random_projection_split(data, indices, rng_state):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/home/debnatho/anaconda3/envs/scanpy_scgen/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: \u001b[1m\u001b[1m\n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\u001b[1m\n",
      "File \"../../../../../home/debnatho/anaconda3/envs/scanpy_scgen/lib/python3.6/site-packages/umap/utils.py\", line 409:\u001b[0m\n",
      "\u001b[1m@numba.njit(parallel=True)\n",
      "\u001b[1mdef build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  current_graph, n_vertices, n_neighbors, max_candidates, rng_state\n",
      "/home/debnatho/anaconda3/envs/scanpy_scgen/lib/python3.6/site-packages/numba/typed_passes.py:293: NumbaPerformanceWarning: \u001b[1m\n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\u001b[1m\n",
      "File \"../../../../../home/debnatho/anaconda3/envs/scanpy_scgen/lib/python3.6/site-packages/umap/nndescent.py\", line 47:\u001b[0m\n",
      "\u001b[1m    @numba.njit(parallel=True)\n",
      "\u001b[1m    def nn_descent(\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "🧙 Majority voting\n",
      "✅ Majority voting done!\n"
     ]
    }
   ],
   "source": [
    "#test data: latest Cellbdender filtered decidua object (SP136 samples were not sequenced at this point)\n",
    "#Model: trained on decidua controls. \n",
    "#Logistic Regression classifier used as implemented in CellTypist. \n",
    "predictions = celltypist.annotate(filename= \"/data/analysis/preeclampsia_2019/placenta_atlas_2022/decidua_anndata/Decidua_cellbender_normalized_matrix_270122.h5ad\", \n",
    "                                  model = '/data/analysis/preeclampsia_2019/placenta_atlas_2022/placenta_celltypist_model/model_from_sp014_control_decidua.pkl', \n",
    "                                  majority_voting = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted labels</th>\n",
       "      <th>over clustering</th>\n",
       "      <th>predicted labels after majority voting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACGTCAACAAGGACAC-1-0</th>\n",
       "      <td>dEpC</td>\n",
       "      <td>252</td>\n",
       "      <td>dEpC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTAGGACCACACAGAG-1-0</th>\n",
       "      <td>DSC_2</td>\n",
       "      <td>96</td>\n",
       "      <td>DSC_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATCATCTTCCTTTCGG-1-0</th>\n",
       "      <td>dEpC</td>\n",
       "      <td>76</td>\n",
       "      <td>dEpC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATCTACTGTTCCTCCA-1-0</th>\n",
       "      <td>DSC_1</td>\n",
       "      <td>145</td>\n",
       "      <td>dMSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTATGCTTCATTGCCC-1-0</th>\n",
       "      <td>dEpC</td>\n",
       "      <td>139</td>\n",
       "      <td>dEpC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACTGGTAGCGACGTA-1-8</th>\n",
       "      <td>dMAC_activated</td>\n",
       "      <td>47</td>\n",
       "      <td>dMAC_activated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACTCAGAGCAACGGT-1-8</th>\n",
       "      <td>dMAC_activated</td>\n",
       "      <td>217</td>\n",
       "      <td>dMAC_activated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTTGGCTCACCTGGTG-1-8</th>\n",
       "      <td>dMAC_activated</td>\n",
       "      <td>58</td>\n",
       "      <td>dMAC_activated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAGTCCTAGAATTCCC-1-8</th>\n",
       "      <td>dMAC_activated</td>\n",
       "      <td>20</td>\n",
       "      <td>dMAC_activated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAAGCGTGTTGTGGAG-1-8</th>\n",
       "      <td>dMAC_activated</td>\n",
       "      <td>20</td>\n",
       "      <td>dMAC_activated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44232 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     predicted labels over clustering  \\\n",
       "ACGTCAACAAGGACAC-1-0             dEpC             252   \n",
       "TTAGGACCACACAGAG-1-0            DSC_2              96   \n",
       "ATCATCTTCCTTTCGG-1-0             dEpC              76   \n",
       "ATCTACTGTTCCTCCA-1-0            DSC_1             145   \n",
       "TTATGCTTCATTGCCC-1-0             dEpC             139   \n",
       "...                               ...             ...   \n",
       "AACTGGTAGCGACGTA-1-8   dMAC_activated              47   \n",
       "AACTCAGAGCAACGGT-1-8   dMAC_activated             217   \n",
       "CTTGGCTCACCTGGTG-1-8   dMAC_activated              58   \n",
       "CAGTCCTAGAATTCCC-1-8   dMAC_activated              20   \n",
       "TAAGCGTGTTGTGGAG-1-8   dMAC_activated              20   \n",
       "\n",
       "                     predicted labels after majority voting  \n",
       "ACGTCAACAAGGACAC-1-0                                   dEpC  \n",
       "TTAGGACCACACAGAG-1-0                                  DSC_2  \n",
       "ATCATCTTCCTTTCGG-1-0                                   dEpC  \n",
       "ATCTACTGTTCCTCCA-1-0                                   dMSC  \n",
       "TTATGCTTCATTGCCC-1-0                                   dEpC  \n",
       "...                                                     ...  \n",
       "AACTGGTAGCGACGTA-1-8                         dMAC_activated  \n",
       "AACTCAGAGCAACGGT-1-8                         dMAC_activated  \n",
       "CTTGGCTCACCTGGTG-1-8                         dMAC_activated  \n",
       "CAGTCCTAGAATTCCC-1-8                         dMAC_activated  \n",
       "TAAGCGTGTTGTGGAG-1-8                         dMAC_activated  \n",
       "\n",
       "[44232 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dNK_1             8490\n",
       "dMAC_classical    7716\n",
       "dEpC              7203\n",
       "dTcell            6112\n",
       "dLEC              2981\n",
       "dMAC_activated    2938\n",
       "dNK_2             2051\n",
       "dVEC              1774\n",
       "DSC_1             1170\n",
       "dSMC               860\n",
       "dPlasmaCell        557\n",
       "dMSC               476\n",
       "dSCT               456\n",
       "dGranulocyte       348\n",
       "DSC_2              292\n",
       "dFB_1              169\n",
       "dNK_prol           161\n",
       "dFB_2              160\n",
       "dDC                160\n",
       "dEVT               158\n",
       "Name: predicted labels after majority voting, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_test= sc.read_h5ad(\"/data/analysis/preeclampsia_2019/placenta_atlas_2022/decidua_anndata/Decidua_cellbender_normalized_matrix_270122.h5ad\")\n",
    "\n",
    "adata_annot= adata_test.copy()\n",
    "adata_annot.obs= predictions.predicted_labels #Write the \"predicted_labels\" in the metadata. \n",
    "adata_annot.obs['predicted labels after majority voting'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dNK_1             8490\n",
       "dMAC_classical    7716\n",
       "dEpC              7203\n",
       "dTcell            6112\n",
       "dLEC              2981\n",
       "dMAC_activated    2938\n",
       "dNK_2             2051\n",
       "dVEC              1774\n",
       "DSC_1             1170\n",
       "dSMC               860\n",
       "dPlasmaCell        557\n",
       "dMSC               476\n",
       "dSCT               456\n",
       "dGranulocyte       348\n",
       "DSC_2              292\n",
       "dFB_1              169\n",
       "dNK_prol           161\n",
       "dFB_2              160\n",
       "dDC                160\n",
       "dEVT               158\n",
       "Name: majority_voting, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write the predicted celltypist labels as a .obs class: \n",
    "adata_test.obs['majority_voting']= adata_annot.obs['predicted labels after majority voting']\n",
    "adata_test.obs['predicted_labels']= adata_annot.obs['predicted labels']\n",
    "adata_test.obs['majority_voting'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'maternal_BMI' as categorical\n",
      "... storing 'maternal_age' as categorical\n",
      "... storing 'majority_voting' as categorical\n",
      "... storing 'predicted_labels' as categorical\n"
     ]
    }
   ],
   "source": [
    "results_annot= \"/data/analysis/preeclampsia_2019/placenta_atlas_2022/placenta_celltypist_model/Decidua_atlas_celltypist_annotated_2701.h5ad\" #should we replace it? \n",
    "adata_test.write(results_annot)\n",
    "\n",
    "#If more PE samples are added, we've to either repeat this or use scANVI for label-transfer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
